{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The example demonstrates how to write custom layers for Keras.\\n\\nWe build a custom activation layer called 'Antirectifier',\\nwhich modifies the shape of the tensor that passes through it.\\n\\nWe need to specify two methods: `compute_output_shape` and `call`.\\nNote that the same result can also be achieved via a Lambda layer.\\n\\nBecause our custom layer is written with primitives from the Keras\\nbackend (`K`), our code can run both on TensorFlow and Theano.\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''The example demonstrates how to write custom layers for Keras.\n",
    "\n",
    "We build a custom activation layer called 'Antirectifier',\n",
    "which modifies the shape of the tensor that passes through it.\n",
    "\n",
    "We need to specify two methods: `compute_output_shape` and `call`.\n",
    "Note that the same result can also be achieved via a Lambda layer.\n",
    "\n",
    "Because our custom layer is written with primitives from the Keras\n",
    "backend (`K`), our code can run both on TensorFlow and Theano.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Antirectifier(layers.Layer):\n",
    "    '''This is the combination of a sample-wise\n",
    "    L2 normalization with the concatenation of the\n",
    "    positive part of the input with the negative part\n",
    "    of the input. The result is a tensor of samples that are\n",
    "    twice as large as the input samples.\n",
    "    It can be used in place of a ReLU.\n",
    "    # Input shape\n",
    "        2D tensor of shape (samples, n)\n",
    "    # Output shape\n",
    "        2D tensor of shape (samples, 2*n)\n",
    "    # Theoretical justification\n",
    "        When applying ReLU, assuming that the distribution\n",
    "        of the previous output is approximately centered around 0.,\n",
    "        you are discarding half of your input. This is inefficient.\n",
    "        Antirectifier allows to return all-positive outputs like ReLU,\n",
    "        without discarding any data.\n",
    "        Tests on MNIST show that Antirectifier allows to train networks\n",
    "        with twice less parameters yet with comparable\n",
    "        classification accuracy as an equivalent ReLU-based network.\n",
    "    '''\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        shape = list(input_shape)\n",
    "        assert len(shape) == 2  # only valid for 2D tensors\n",
    "        shape[-1] *= 2\n",
    "        return tuple(shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs -= K.mean(inputs, axis=1, keepdims=True)\n",
    "        inputs = K.l2_normalize(inputs, axis=1)\n",
    "        pos = K.relu(inputs)\n",
    "        neg = K.relu(-inputs)\n",
    "        return K.concatenate([pos, neg], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables initialization\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Good source for datasets\n",
    "# https://s3.amazonaws.com/img-datasets/mnist.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 784)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Preprocess data\n",
    "'''\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "'''\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.6049 - acc: 0.9161 - val_loss: 0.1658 - val_acc: 0.9577\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1254 - acc: 0.9661 - val_loss: 0.0930 - val_acc: 0.9730\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.0820 - acc: 0.9765 - val_loss: 0.0803 - val_acc: 0.9749\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.0629 - acc: 0.9813 - val_loss: 0.0762 - val_acc: 0.9765\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.0505 - acc: 0.9847 - val_loss: 0.0703 - val_acc: 0.9789\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.0426 - acc: 0.9873 - val_loss: 0.0738 - val_acc: 0.9783\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.0351 - acc: 0.9896 - val_loss: 0.0746 - val_acc: 0.9771\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.0299 - acc: 0.9909 - val_loss: 0.0678 - val_acc: 0.9802\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.0276 - acc: 0.9917 - val_loss: 0.0749 - val_acc: 0.9794\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.0246 - acc: 0.9925 - val_loss: 0.0697 - val_acc: 0.9802\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.0216 - acc: 0.9932 - val_loss: 0.0768 - val_acc: 0.9801\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.0195 - acc: 0.9936 - val_loss: 0.0725 - val_acc: 0.9811\n",
      "Test loss: 0.07247698889567983\n",
      "Test accuracy: 0.9811\n"
     ]
    }
   ],
   "source": [
    "# Model Building\n",
    "\n",
    "# build the model\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(256, input_shape=(784,)))\n",
    "model.add(Antirectifier())\n",
    "model.add(layers.Dropout(0.1))\n",
    "model.add(layers.Dense(256))\n",
    "model.add(Antirectifier())\n",
    "model.add(layers.Dropout(0.1))\n",
    "model.add(layers.Dense(num_classes))\n",
    "model.add(layers.Activation('softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "# next, compare with an equivalent network\n",
    "# with2x bigger Dense layers and ReLU\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "antirectifier_1 (Antirectifi (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "antirectifier_2 (Antirectifi (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 337,418\n",
      "Trainable params: 337,418\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model Summary\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
